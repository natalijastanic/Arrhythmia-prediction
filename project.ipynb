{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "869169a2-00d6-42e3-a7d2-777d0ec5f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec624a-23a6-42de-818d-7334602cfade",
   "metadata": {},
   "source": [
    "## 1) Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c801b88-4e87-4045-85d5-ae016349df57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>qrs_duration</th>\n",
       "      <th>p-r_interval</th>\n",
       "      <th>q-t_interval</th>\n",
       "      <th>t_interval</th>\n",
       "      <th>p_interval</th>\n",
       "      <th>qrs</th>\n",
       "      <th>...</th>\n",
       "      <th>KY</th>\n",
       "      <th>KZ</th>\n",
       "      <th>LA</th>\n",
       "      <th>LB</th>\n",
       "      <th>LC</th>\n",
       "      <th>LD</th>\n",
       "      <th>LE</th>\n",
       "      <th>LF</th>\n",
       "      <th>LG</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>167</td>\n",
       "      <td>321</td>\n",
       "      <td>174</td>\n",
       "      <td>91</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>52</td>\n",
       "      <td>77</td>\n",
       "      <td>129</td>\n",
       "      <td>377</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>20.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>54</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>376</td>\n",
       "      <td>157</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>56</td>\n",
       "      <td>84</td>\n",
       "      <td>118</td>\n",
       "      <td>354</td>\n",
       "      <td>160</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>30.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "      <td>67</td>\n",
       "      <td>89</td>\n",
       "      <td>130</td>\n",
       "      <td>383</td>\n",
       "      <td>156</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>10.8</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.1</td>\n",
       "      <td>25.1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  height  weight  qrs_duration  p-r_interval  q-t_interval  \\\n",
       "0   75    0     190      80            91           193           371   \n",
       "1   56    1     165      64            81           174           401   \n",
       "2   54    0     172      95           138           163           386   \n",
       "3   55    0     175      94           100           202           380   \n",
       "4   75    0     190      80            88           181           360   \n",
       "5   13    0     169      51           100           167           321   \n",
       "6   40    1     160      52            77           129           377   \n",
       "7   49    1     162      54            78             0           376   \n",
       "8   44    0     168      56            84           118           354   \n",
       "9   50    1     167      67            89           130           383   \n",
       "\n",
       "   t_interval  p_interval  qrs  ...   KY    KZ   LA   LB LC   LD   LE    LF  \\\n",
       "0         174         121  -16  ...  0.0   9.0 -0.9  0.0  0  0.9  2.9  23.3   \n",
       "1         149          39   25  ...  0.0   8.5  0.0  0.0  0  0.2  2.1  20.4   \n",
       "2         185         102   96  ...  0.0   9.5 -2.4  0.0  0  0.3  3.4  12.3   \n",
       "3         179         143   28  ...  0.0  12.2 -2.2  0.0  0  0.4  2.6  34.6   \n",
       "4         177         103  -16  ...  0.0  13.1 -3.6  0.0  0 -0.1  3.9  25.4   \n",
       "5         174          91  107  ... -0.6  12.2 -2.8  0.0  0  0.9  2.2  13.5   \n",
       "6         133          77   77  ...  0.0   6.5  0.0  0.0  0  0.4  1.0  14.3   \n",
       "7         157          70   67  ...  0.0   8.2 -1.9  0.0  0  0.1  0.5  15.8   \n",
       "8         160          63   61  ...  0.0   7.0 -1.3  0.0  0  0.6  2.1  12.5   \n",
       "9         156          73   85  ... -0.6  10.8 -1.7  0.0  0  0.8  0.9  20.1   \n",
       "\n",
       "     LG  diagnosis  \n",
       "0  49.4          8  \n",
       "1  38.8          6  \n",
       "2  49.0         10  \n",
       "3  61.6          1  \n",
       "4  62.8          7  \n",
       "5  31.1         14  \n",
       "6  20.5          1  \n",
       "7  19.8          1  \n",
       "8  30.9          1  \n",
       "9  25.1         10  \n",
       "\n",
       "[10 rows x 280 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('01_arrhythmia_dataset.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2ae900-5662-49b3-b365-0950d8d0bbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 452 entries, 0 to 451\n",
      "Columns: 280 entries, age to diagnosis\n",
      "dtypes: float64(116), int64(159), object(5)\n",
      "memory usage: 988.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa976026-64d6-45ac-88b6-eaed26c9b63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUICK CHECK: COLUMNS 10-14 (VECTOR ANGLES)\n",
      "============================================================\n",
      "\n",
      "Column 10:\n",
      "  Type: object\n",
      "  Contains '?': 8\n",
      "  Sample values: ['13', '37', '34', '11', '13', '66', '49', '7', '69', '34']\n",
      "\n",
      "Column 11:\n",
      "  Type: object\n",
      "  Contains '?': 22\n",
      "  Sample values: ['64', '-17', '70', '-5', '61', '52', '75', '8', '78', '70']\n",
      "\n",
      "Column 12:\n",
      "  Type: object\n",
      "  Contains '?': 1\n",
      "  Sample values: ['-2', '31', '66', '20', '3', '88', '65', '51', '66', '71']\n",
      "\n",
      "Column 13:\n",
      "  Type: object\n",
      "  Contains '?': 376\n",
      "  Sample values: ['?', '?', '23', '?', '?', '?', '?', '?', '84', '?']\n",
      "\n",
      "Column 14:\n",
      "  Type: object\n",
      "  Contains '?': 1\n",
      "  Sample values: ['63', '53', '75', '71', '?', '84', '70', '67', '64', '63']\n",
      "============================================================\n",
      "ANALYSIS OF INVALID VALUES\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Quick check only for columns 10-14\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUICK CHECK: COLUMNS 10-14 (VECTOR ANGLES)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col_idx in range(10, 15):\n",
    "    col = data.iloc[:, col_idx]\n",
    "    print(f\"\\nColumn {col_idx}:\")\n",
    "    print(f\"  Type: {col.dtype}\")\n",
    "    \n",
    "    if col.dtype == 'object':\n",
    "        print(f\"  Contains '?': {(col == '?').sum()}\")\n",
    "        print(f\"  Sample values: {col.head(10).tolist()}\")\n",
    "    else:\n",
    "        print(f\"  Min: {col.min()}, Max: {col.max()}\")\n",
    "        print(f\"  NaN count: {col.isna().sum()}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS OF INVALID VALUES\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80cc513-f371-41a6-914f-f750c13b8d6d",
   "metadata": {},
   "source": [
    "### Problem Analysis\n",
    "\n",
    "- **Column 10 (index 10):** 8 `'?'` values – *small*, fill with median  \n",
    "- **Column 11 (index 11):** 22 `'?'` values – *small*, fill with median  \n",
    "- **Column 12 (index 12):** 1 `'?'` value – *negligible*, fill with median  \n",
    "- **Column 13 (index 13):** 376 `'?'` values – **HUGE** (almost 84%!)  \n",
    "- **Column 14 (index 14):** 1 `'?'` value – *negligible*, fill with median\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1d430-cbe7-4c31-b770-3851376e9e93",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Strategy\n",
    "\n",
    "- **Column 13 – REMOVE!** (376/452 = 83% missing!)  \n",
    "  A column with over 50% missing values is useless and should be dropped.  \n",
    "- **Other columns – FILL with median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212c5765-350d-4f7f-a864-f788b43d51e7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column 13 (index 13) - J angle:\n",
      "'?' values: 376/452 (83.2%)\n",
      "DECISION: DROP this column (>50% missing)\n",
      "Reason: Too many missing values make this attribute unreliable\n",
      "Column 13 removed\n",
      "New shape: (452, 279)\n",
      "\n",
      "============================================================\n",
      "PROCESSING OTHER COLUMNS:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Column index 10:\n",
      "   '?' values before: 8\n",
      "Replaced 8 missing values with median: 41.00\n",
      "New type: float64\n",
      "\n",
      "Column index 11:\n",
      "   '?' values before: 22\n",
      "Replaced 22 missing values with median: 56.00\n",
      "New type: float64\n",
      "\n",
      "Column index 12:\n",
      "   '?' values before: 1\n",
      "Replaced 1 missing values with median: 40.00\n",
      "New type: float64\n",
      "\n",
      "Column index 13:\n",
      "   '?' values before: 1\n",
      "Replaced 1 missing values with median: 72.00\n",
      "New type: float64\n",
      "\n",
      "============================================================\n",
      "FINAL VERIFICATION:\n",
      "------------------------------------------------------------\n",
      "Original shape: (452, 280)\n",
      "New shape: (452, 279)\n",
      "Columns removed: 1\n",
      "Total NaN remaining: 0\n",
      "\n",
      "Data type summary:\n",
      "int64      159\n",
      "float64    120\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cleaned data saved to 'data_cleaned_columns_10_14.csv'\n",
      "\n",
      "============================================================\n",
      "SUMMARY OF ACTIONS:\n",
      "------------------------------------------------------------\n",
      "Column 13 (J angle): REMOVED (83% missing)\n",
      "Column 10 (T angle): Filled 8 missing values with median\n",
      "Column 11 (P angle): Filled 22 missing values with median\n",
      "Column 12 (QRST angle): Filled 1 missing value with median\n",
      "Column 14 (Heart rate): Filled 1 missing value with median\n",
      "All columns converted to numeric type\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create clean copy\n",
    "data_clean = data.copy()\n",
    "\n",
    "# 1. CHECK COLUMN 13 (index 13) - J angle\n",
    "col_13 = data_clean.iloc[:, 13]\n",
    "qm_count_13 = (col_13 == '?').sum()\n",
    "total_rows = len(data_clean)\n",
    "missing_percent_13 = (qm_count_13 / total_rows) * 100\n",
    "\n",
    "print(f\"\\nColumn 13 (index 13) - J angle:\")\n",
    "print(f\"'?' values: {qm_count_13}/{total_rows} ({missing_percent_13:.1f}%)\")\n",
    "\n",
    "if missing_percent_13 > 50:\n",
    "    print(f\"DECISION: DROP this column (>50% missing)\")\n",
    "    print(f\"Reason: Too many missing values make this attribute unreliable\")\n",
    "    \n",
    "    # Drop column 13\n",
    "    data_clean = data_clean.drop(data_clean.columns[13], axis=1)\n",
    "    print(f\"Column 13 removed\")\n",
    "    print(f\"New shape: {data_clean.shape}\")\n",
    "else:\n",
    "    print(f\"DECISION: KEEP and fill with median\")\n",
    "\n",
    "# 2. CLEAN REMAINING COLUMNS (10, 11, 12, 14)\n",
    "# Note: After dropping column 13, column 14 becomes column 13!\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PROCESSING OTHER COLUMNS:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Columns to process (adjust indices if column 13 was dropped)\n",
    "if missing_percent_13 > 50:\n",
    "    # Column 13 was dropped, so now we have:\n",
    "    # Old index 10 → still 10\n",
    "    # Old index 11 → still 11  \n",
    "    # Old index 12 → still 12\n",
    "    # Old index 14 → now 13!\n",
    "    columns_to_clean = [10, 11, 12, 13]  # adjusted indices\n",
    "else:\n",
    "    columns_to_clean = [10, 11, 12, 13, 14]\n",
    "\n",
    "for col_idx in columns_to_clean:\n",
    "    if col_idx < len(data_clean.columns) - 1:  # Don't touch target column\n",
    "        col_name = data_clean.columns[col_idx]\n",
    "        col = data_clean[col_name]\n",
    "        \n",
    "        print(f\"\\nColumn index {col_idx}:\")\n",
    "        \n",
    "        # Count '?' before\n",
    "        qm_before = (col == '?').sum() if col.dtype == 'object' else 0\n",
    "        print(f\"   '?' values before: {qm_before}\")\n",
    "        \n",
    "        # Step 1: Replace '?' with NaN\n",
    "        data_clean[col_name] = data_clean[col_name].replace('?', np.nan)\n",
    "        \n",
    "        # Step 2: Convert to numeric\n",
    "        data_clean[col_name] = pd.to_numeric(data_clean[col_name], errors='coerce')\n",
    "        \n",
    "        # Step 3: Fill NaN with median\n",
    "        if data_clean[col_name].isna().any():\n",
    "            median_val = data_clean[col_name].median()\n",
    "            nan_count = data_clean[col_name].isna().sum()\n",
    "            data_clean[col_name].fillna(median_val, inplace=True)\n",
    "            \n",
    "            print(f\"Replaced {nan_count} missing values with median: {median_val:.2f}\")\n",
    "            print(f\"New type: {data_clean[col_name].dtype}\")\n",
    "        else:\n",
    "            print(f\"No missing values\")\n",
    "\n",
    "# 3. FINAL VERIFICATION\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FINAL VERIFICATION:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "print(f\"Original shape: {data.shape}\")\n",
    "print(f\"New shape: {data_clean.shape}\")\n",
    "print(f\"Columns removed: {data.shape[1] - data_clean.shape[1]}\")\n",
    "\n",
    "# Check for remaining '?' or NaN\n",
    "total_nan = data_clean.isna().sum().sum()\n",
    "print(f\"Total NaN remaining: {total_nan}\")\n",
    "\n",
    "# Check data types\n",
    "print(f\"\\nData type summary:\")\n",
    "print(data_clean.dtypes.value_counts())\n",
    "\n",
    "# Save cleaned data\n",
    "data_clean.to_csv('data_cleaned_columns_10_14.csv', index=False)\n",
    "print(f\"\\nCleaned data saved to 'data_cleaned_columns_10_14.csv'\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY OF ACTIONS:\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Column 13 (J angle): REMOVED (83% missing)\")\n",
    "print(f\"Column 10 (T angle): Filled 8 missing values with median\")\n",
    "print(f\"Column 11 (P angle): Filled 22 missing values with median\")\n",
    "print(f\"Column 12 (QRST angle): Filled 1 missing value with median\")\n",
    "print(f\"Column 14 (Heart rate): Filled 1 missing value with median\")\n",
    "print(f\"All columns converted to numeric type\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e675bfc5-ffa4-4aec-954b-89ce12cf318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BIOMETRIC DATA:\n",
      "------------------------------------------------------------\n",
      "\n",
      "AGE (column 0):\n",
      "   Min: 0, Max: 83\n",
      "   Mean: 46.5, Std: 16.5\n",
      "All values are in valid range (0-120)\n",
      "\n",
      "SEX (column 1):\n",
      "   Unique values: [0 1]\n",
      "All values are valid (0 or 1)\n",
      "\n",
      "HEIGHT (column 2):\n",
      "   Min: 105, Max: 780\n",
      "   Mean: 166.2, Std: 37.2\n",
      "Found 2 invalid values!\n",
      "   Values: [780, 608]\n",
      "\n",
      "WEIGHT (column 3):\n",
      "   Min: 6, Max: 176\n",
      "   Mean: 68.2, Std: 16.6\n",
      "All values are in valid range (4-200 kg)\n",
      "\n",
      "HEART RATE (column 13):\n",
      "   Min: 44.0, Max: 163.0\n",
      "   Mean: 74.5, Std: 13.9\n",
      "All values are in valid range (30-220 bpm)\n"
     ]
    }
   ],
   "source": [
    "# Define columns according to documentation\n",
    "col_names = {\n",
    "    0: 'Age',\n",
    "    1: 'Sex', \n",
    "    2: 'Height',\n",
    "    3: 'Weight',\n",
    "    4: 'QRS_duration',\n",
    "    5: 'PR_interval',\n",
    "    6: 'QT_interval',\n",
    "    7: 'T_interval',\n",
    "    8: 'P_interval',\n",
    "    13: 'Heart_rate'\n",
    "}\n",
    "\n",
    "# 1. CHECK BASIC BIOMETRIC DATA\n",
    "print(\"\\nBIOMETRIC DATA:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Age (0-120 years is realistic)\n",
    "age_col = data_clean.iloc[:, 0]\n",
    "print(f\"\\nAGE (column 0):\")\n",
    "print(f\"   Min: {age_col.min()}, Max: {age_col.max()}\")\n",
    "print(f\"   Mean: {age_col.mean():.1f}, Std: {age_col.std():.1f}\")\n",
    "\n",
    "invalid_age = data_clean[(age_col < 0) | (age_col > 120)]\n",
    "if len(invalid_age) > 0:\n",
    "    print(f\"Found {len(invalid_age)} invalid values!\")\n",
    "    print(f\"   Values: {age_col[invalid_age.index].tolist()}\")\n",
    "else:\n",
    "    print(f\"All values are in valid range (0-120)\")\n",
    "\n",
    "# Sex (0 or 1)\n",
    "sex_col = data_clean.iloc[:, 1]\n",
    "print(f\"\\nSEX (column 1):\")\n",
    "print(f\"   Unique values: {sex_col.unique()}\")\n",
    "invalid_sex = data[~sex_col.isin([0, 1])]\n",
    "if len(invalid_sex) > 0:\n",
    "    print(f\"Found {len(invalid_sex)} invalid values!\")\n",
    "else:\n",
    "    print(f\"All values are valid (0 or 1)\")\n",
    "\n",
    "# Height (100-250 cm is realistic)\n",
    "height_col = data_clean.iloc[:, 2]\n",
    "print(f\"\\nHEIGHT (column 2):\")\n",
    "print(f\"   Min: {height_col.min()}, Max: {height_col.max()}\")\n",
    "print(f\"   Mean: {height_col.mean():.1f}, Std: {height_col.std():.1f}\")\n",
    "\n",
    "invalid_height = data_clean[(height_col < 100) | (height_col > 250)]\n",
    "if len(invalid_height) > 0:\n",
    "    print(f\"Found {len(invalid_height)} invalid values!\")\n",
    "    print(f\"   Values: {height_col[invalid_height.index].tolist()}\")\n",
    "else:\n",
    "    print(f\"All values are in valid range (100-250 cm)\")\n",
    "    \n",
    "# Weight (30-200 kg is realistic)\n",
    "weight_col = data_clean.iloc[:, 3]\n",
    "print(f\"\\nWEIGHT (column 3):\")\n",
    "print(f\"   Min: {weight_col.min()}, Max: {weight_col.max()}\")\n",
    "print(f\"   Mean: {weight_col.mean():.1f}, Std: {weight_col.std():.1f}\")\n",
    "\n",
    "invalid_weight = data_clean[(weight_col < 4) | (weight_col > 200)]\n",
    "if len(invalid_weight) > 0:\n",
    "    print(f\"Found {len(invalid_weight)} invalid values!\")\n",
    "    print(f\"   Values: {weight_col[invalid_weight.index].tolist()}\")\n",
    "else:\n",
    "    print(f\"All values are in valid range (4-200 kg)\")\n",
    "\n",
    "# Heart rate (30-220 beats/min is realistic)\n",
    "hr_col = data_clean.iloc[:, 13]\n",
    "print(f\"\\nHEART RATE (column 13):\")\n",
    "print(f\"   Min: {hr_col.min()}, Max: {hr_col.max()}\")\n",
    "print(f\"   Mean: {hr_col.mean():.1f}, Std: {hr_col.std():.1f}\")\n",
    "\n",
    "invalid_hr = data_clean[(hr_col < 30) | (hr_col > 220)]\n",
    "if len(invalid_hr) > 0:\n",
    "    print(f\"Found {len(invalid_hr)} invalid values!\")\n",
    "    print(f\"   Values: {hr_col[invalid_hr.index].tolist()}\")\n",
    "else:\n",
    "    print(f\"All values are in valid range (30-220 bpm)\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f99cae3-70c2-4eeb-8253-082e2879373a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PROCESSING MINORITY CLASSES\n",
      "============================================================\n",
      "\n",
      "ORIGINAL DISTRIBUTION:\n",
      "------------------------------------------------------------\n",
      "Class  1: 245 instances (54.20%)\n",
      "Class  2:  44 instances ( 9.73%)\n",
      "Class  3:  15 instances ( 3.32%)\n",
      "Class  4:  15 instances ( 3.32%)\n",
      "Class  5:  13 instances ( 2.88%)\n",
      "Class  6:  25 instances ( 5.53%)\n",
      "Class  7:   3 instances ( 0.66%)\n",
      "Class  8:   2 instances ( 0.44%)\n",
      "Class  9:   9 instances ( 1.99%)\n",
      "Class 10:  50 instances (11.06%)\n",
      "Class 14:   4 instances ( 0.88%)\n",
      "Class 15:   5 instances ( 1.11%)\n",
      "Class 16:  22 instances ( 4.87%)\n",
      "\n",
      "============================================================\n",
      "MINORITY CLASSES (< 3.0%):\n",
      "------------------------------------------------------------\n",
      "Class  5:  13 instanci ( 2.88%) → TRANSFERS TO 16\n",
      "Class  7:   3 instanci ( 0.66%) → TRANSFERS TO 16\n",
      "Class  8:   2 instanci ( 0.44%) → TRANSFERS TO 16\n",
      "Class  9:   9 instanci ( 1.99%) → TRANSFERS TO 16\n",
      "Class 14:   4 instanci ( 0.88%) → TRANSFERS TO 16\n",
      "Class 15:   5 instanci ( 1.11%) → TRANSFERS TO 16\n",
      "\n",
      "Total minority classes: 6\n",
      "\n",
      "============================================================\n",
      "UNITE MINORITY CLASSES TO 16 (Others):\n",
      "------------------------------------------------------------\n",
      "Class  5 → 16: 13 insstances\n",
      "Class  7 → 16: 3 insstances\n",
      "Class  8 → 16: 2 insstances\n",
      "Class  9 → 16: 9 insstances\n",
      "Class 14 → 16: 4 insstances\n",
      "Class 15 → 16: 5 insstances\n",
      "\n",
      "Total instances transfered: 36\n",
      "\n",
      "============================================================\n",
      "NEW DISTRIBUTION (after uniting):\n",
      "------------------------------------------------------------\n",
      "Class  1: 245 instances (54.20%)\n",
      "Class  2:  44 instances ( 9.73%)\n",
      "Class  3:  15 instances ( 3.32%)\n",
      "Class  4:  15 instances ( 3.32%)\n",
      "Class  6:  25 instances ( 5.53%)\n",
      "Class 10:  50 instances (11.06%)\n",
      "Class 16 (Others):  58 instances (12.83%) \n",
      "\n",
      "============================================================\n",
      "FINAL RESULT:\n",
      "------------------------------------------------------------\n",
      "Original number of classes: 13\n",
      "Final number of classes: 7\n",
      "Reduction: 6 klasa\n",
      "\n",
      "Final classes: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(6), np.int64(10), np.int64(16)]\n",
      "\n",
      "Saved to 'data_final.csv'\n"
     ]
    }
   ],
   "source": [
    "# Last column is diagnosis (class)\n",
    "target_col = data_clean.columns[-1]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PROCESSING MINORITY CLASSES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Originalna distribucija\n",
    "print(\"\\nORIGINAL DISTRIBUTION:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "total_instances = len(data_clean)\n",
    "class_counts = data[target_col].value_counts().sort_index()\n",
    "\n",
    "for cls in sorted(data_clean[target_col].unique()):\n",
    "    count = class_counts[cls]\n",
    "    percent = (count / total_instances) * 100\n",
    "    print(f\"Class {cls:2d}: {count:3d} instances ({percent:5.2f}%)\")\n",
    "\n",
    "# 2. Identify minority classes (< 3%)\n",
    "minority_threshold = 3.0\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MINORITY CLASSES (< {minority_threshold}%):\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "minority_classes = []\n",
    "for cls in sorted(data_clean[target_col].unique()):\n",
    "    count = class_counts[cls]\n",
    "    percent = (count / total_instances) * 100\n",
    "    \n",
    "    if percent < minority_threshold and cls != 16:  # NE diraj klasu 16 (već je Others)\n",
    "        minority_classes.append(cls)\n",
    "        print(f\"Class {cls:2d}: {count:3d} instanci ({percent:5.2f}%) → TRANSFERS TO 16\")\n",
    "\n",
    "print(f\"\\nTotal minority classes: {len(minority_classes)}\")\n",
    "\n",
    "# 3. Unite minority classes to 16 (Others)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"UNITE MINORITY CLASSES TO 16 (Others):\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Transfer all minority classes to 16\n",
    "total_moved = 0\n",
    "for cls in minority_classes:\n",
    "    count = (data_clean[target_col] == cls).sum()\n",
    "    data_clean.loc[data_clean[target_col] == cls, target_col] = 16\n",
    "    total_moved += count\n",
    "    print(f\"Class {cls:2d} → 16: {count} insstances\")\n",
    "\n",
    "print(f\"\\nTotal instances transfered: {total_moved}\")\n",
    "\n",
    "# 4. New distribution\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"NEW DISTRIBUTION (after uniting):\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "final_counts = data_clean[target_col].value_counts().sort_index()\n",
    "\n",
    "for cls in sorted(data_clean[target_col].unique()):\n",
    "    count = final_counts[cls]\n",
    "    percent = (count / len(data_clean)) * 100\n",
    "    \n",
    "    if cls == 16:\n",
    "        print(f\"Class {cls:2d} (Others): {count:3d} instances ({percent:5.2f}%) \")\n",
    "    else:\n",
    "        print(f\"Class {cls:2d}: {count:3d} instances ({percent:5.2f}%)\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL RESULT:\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Original number of classes: {data[target_col].nunique()}\")\n",
    "print(f\"Final number of classes: {data_clean[target_col].nunique()}\")\n",
    "print(f\"Reduction: {data[target_col].nunique() - data_clean[target_col].nunique()} klasa\")\n",
    "print(f\"\\nFinal classes: {sorted(data_clean[target_col].unique())}\")\n",
    "\n",
    "# 5. Save clean data\n",
    "data_clean.to_csv('data_final.csv', index=False)\n",
    "print(f\"\\nSaved to 'data_final.csv'\")\n",
    "data_clean_final = data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad2068f-b9ff-4d98-9486-0d71405df61b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2) Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2249b86-6a39-4cae-a43d-3cf36f5d6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateInfoD(col):\n",
    "    un = np.unique(col)\n",
    "    infoD = 0\n",
    "    for u in un:\n",
    "        p = sum(col == u)/len(col)\n",
    "        infoD -= p*np.log2(p)\n",
    "    return infoD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7102c936-6455-4c14-ad1f-a2a82d8db9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def informationGain(feat):\n",
    "    numberOfSteps = 10\n",
    "    classes = data_clean_final.iloc[:, -1]\n",
    "    infoD = calculateInfoD(classes)\n",
    "    \n",
    "    col = data_clean_final.iloc[:, feat]\n",
    "    f = np.unique(col)\n",
    "    \n",
    "    if len(f) > numberOfSteps:\n",
    "            step = (max(col) - min(col))/numberOfSteps\n",
    "            col = np.floor(col/step)*step\n",
    "            f = np.unique(col)\n",
    "                \n",
    "    infoDA = 0\n",
    "    for i in f:\n",
    "        mask = (col == i).values \n",
    "        temp = classes.iloc[mask]\n",
    "    \n",
    "        infoDi = calculateInfoD(temp)\n",
    "        Di = sum(mask)\n",
    "        D = len(col)\n",
    "\n",
    "        infoDA += Di*infoDi/D\n",
    "        \n",
    "    return infoD - infoDA\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ebdc58f-eebc-49ae-92a1-a99cb0e1531c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 COLUMNS BY AVERAGE INFORMATION GAIN:\n",
      "============================================================\n",
      " Index     Column  Average_Information_Gain\n",
      "    13 heart_rate                  0.347994\n",
      "   241         JR                  0.331186\n",
      "   275         LE                  0.314144\n",
      "   112         EB                  0.310474\n",
      "    10          T                  0.300626\n",
      "   175         GU                  0.295567\n",
      "   195         HR                  0.291330\n",
      "   265         KS                  0.288737\n",
      "   100         DM                  0.288149\n",
      "    88         DA                  0.273138\n",
      "\n",
      "\n",
      "\n",
      "SELECTED COLUMN NAMES:\n",
      "['heart_rate', 'JR', 'LE', 'EB', 'T', 'GU', 'HR', 'KS', 'DM', 'DA']\n"
     ]
    }
   ],
   "source": [
    "# Calculate average Information Gain for each column\n",
    "# Each column's IG is measured against all other columns\n",
    "\n",
    "\n",
    "columns = data_clean_final.columns\n",
    "n_cols = len(columns)\n",
    "\n",
    "# Store IG for each column\n",
    "info_gains = []\n",
    "\n",
    "for col in range(data_clean_final.shape[1]-1):\n",
    "    \n",
    "    # Calculate IG\n",
    "    info_gains.append(informationGain(col))\n",
    "\n",
    "# Create results dataframe\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Index': range(len(info_gains)),  # Column index\n",
    "    'Column': columns[:-1],\n",
    "    'Average_Information_Gain': info_gains\n",
    "}).sort_values(by='Average_Information_Gain', ascending=False)\n",
    "\n",
    "# Select top 10\n",
    "top_10 = feature_importance.head(10)\n",
    "\n",
    "print(\"TOP 10 COLUMNS BY AVERAGE INFORMATION GAIN:\")\n",
    "print(\"=\" * 60)\n",
    "print(top_10.to_string(index=False))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print just the column names\n",
    "print(\"\\nSELECTED COLUMN NAMES:\")\n",
    "print(top_10['Column'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b367818-6a96-4ebf-b8c8-65dc34a4cbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>JR</th>\n",
       "      <th>LE</th>\n",
       "      <th>EB</th>\n",
       "      <th>T</th>\n",
       "      <th>GU</th>\n",
       "      <th>HR</th>\n",
       "      <th>KS</th>\n",
       "      <th>DM</th>\n",
       "      <th>DA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>48</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "      <td>-7.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>48</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.0</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>20</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.0</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>40</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.0</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>48</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84.0</td>\n",
       "      <td>-48.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>60</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>67.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>44</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64.0</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>44</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>48</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>63.0</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>48</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   heart_rate    JR   LE  EB     T   GU   HR   KS  DM  DA\n",
       "0        63.0 -10.0  2.9  48  13.0  1.5 -1.7  3.9  52   0\n",
       "1        53.0  -7.7  2.1  48  37.0  1.7 -1.6  2.6  52  52\n",
       "2        75.0  -4.1  3.4  20  34.0  2.7 -2.5  3.4  28  36\n",
       "3        71.0  -7.9  2.6  40  11.0  1.5 -1.7  3.0  44   0\n",
       "4        72.0 -10.2  3.9  48  13.0  1.7 -1.5  2.9  52   0\n",
       "5        84.0 -48.4  2.2  60  66.0  4.3 -2.9  3.3  60  60\n",
       "6        70.0 -11.0  1.0  48  49.0  1.4 -0.9  1.3  56  56\n",
       "7        67.0  -9.0  0.5  44   7.0  0.7 -0.8  0.8  48  44\n",
       "8        64.0 -10.3  2.1  44  69.0  2.8 -1.9  3.8  48  56\n",
       "9        63.0  -7.3  0.9  48  34.0  1.2 -1.2  1.0  44  36"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wanted_col = top_10['Column'].values\n",
    "\n",
    "data_final = data_clean_final[wanted_col]\n",
    "data_final.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69497e0-999d-4d22-ac30-02f7f9e13adb",
   "metadata": {},
   "source": [
    "### Calculate spearman correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ff4689-6045-4233-bf71-a638e29854ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rank(data):\n",
    "    ranked_data = np.zeros(data.shape)\n",
    "    sorted_data = sorted(data)\n",
    "\n",
    "    val, cnt = np.unique(sorted_data, return_counts = True)\n",
    "\n",
    "    r = 1\n",
    "    for i in range(len(val)):\n",
    "        rank = np.mean(np.arrange(r, r+cnt[i]))\n",
    "        pos = np.where(data == val[i])\n",
    "        ranked_data[pos] = rank\n",
    "        \n",
    "        r += cnt[i]\n",
    "        \n",
    "    return ranked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9726b83f-6aff-4914-b4e8-491a1c0f6319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_correlation(x, y):\n",
    "    rank_x = calculate_rank(x)\n",
    "    rank_y = calculate_rank(y)\n",
    "\n",
    "    sprearman = np.cov(rank_x, rank_y)[0,1]/np.std(rank_x)/np.std(rank_y)\n",
    "\n",
    "    return spearman\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98efa1b3-0edb-43f0-9a68-34c4b458d7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
